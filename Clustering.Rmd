---
title: "Clustering"
author: "699 Team"
date: "5/2/2020"
output: html_document
---


## Step IV: Clustering (15 points)
### I. Perform either a k-means analysis or a hierarchical clustering analysis in order to place rentals within your neighborhood into clusters.
** Of any section of the project, this one offers the most opportunity to be creative and take risks. Think about feature engineering, too--how/when/wherecanyou create new variables based on existing ones?



#### Data Preparation for Clustering

```{r}
PB_cluster = PB_3 
```

**1. Drop useless features**
```{r}
PB_cluster = subset(PB_cluster,select =- c(id,name,summary,description,neighborhood_overview,notes,host_verifications,
                                latitude,longitude,transit,access,interaction,house_rules,
                                host_id,host_name,host_about,amenities))
```



```{r}
View(PB_cluster)
```



**2. Missing Value**



square_feet
```{r}
#summary(PB_cluster$square_feet)  # there is too many missing value, therefore, I delete it in 3.(2) part.
PB_cluster$square_feet[is.na(PB_cluster$square_feet) == T] <- "N/A"
PB_cluster$square_feet <-as.factor(PB_cluster$square_feet)
```

security_deposit
I assumed security_deposit is 0 if there is no information about security deposit
```{r}
#summary(PB_cluster$security_deposit)
PB_cluster$security_deposit[is.na(PB_cluster$security_deposit)] <- 0

```

cleaning_fee. I assumed cleaning_fee. is 0 if there is no information about the fee
```{r}
#summary(PB_cluster$cleaning_fee)
PB_cluster$cleaning_fee[is.na(PB_cluster$cleaning_fee)] <- 0
```



reviews
```{r}
# review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_location,  review_scores_value

# no_review_data = PB_cluster[is.na(PB_cluster$review_scores_accuracy) == T,]
review_cols = c("review_scores_rating", "review_scores_accuracy", "review_scores_cleanliness", "review_scores_checkin", "review_scores_communication", "review_scores_location",  "review_scores_value")
for (i in review_cols){
        PB_cluster[i][is.na(PB_cluster[i]) == T] = median(PB_cluster[,i],na.rm = T)
}

# reviews_per_month
PB_cluster$reviews_per_month[is.na(PB_cluster$reviews_per_month) == T] = 0
#summary(PB_cluster$reviews_per_month)

PB_cluster$first_review  = as.factor(PB_cluster$first_review)
#summary(PB_cluster)

```

host_response_rate
```{r}
response_rate = as.numeric(sub("%","",PB_2$host_response_rate))/100
response_rate[is.na(response_rate) == T] = median(response_rate,na.rm = T)
PB_cluster$host_response_rate = response_rate
```



**2. Feature Engineering**
first_review      last_review    
* Here, we created a new feature Business_interval, which measures number of day after this airbnb has first review. 
* Also, we created a feature named No_Business_interval. This measures number of day after the last review. Longer interval means this airbnb is no business recently. 
* The third feature is operation_interval, which is number of day after host_since. This measure how long that the airbnb is.
There are missing value in first_review and last_review the two variables. The reason would be there is no review. Therefore, the time interval would be 0.
```{r}
first_review = as.Date(PB_2$first_review,"%Y-%m-%d")
last_review = as.Date(PB_2$last_review,"%Y-%m-%d")
host_since = as.Date(PB_2$host_since,"%Y-%m-%d")
Business_interval = today() - first_review
No_Business_interval = today() - last_review
operation_interval = today() - host_since

Business_interval[is.na(Business_interval) == T] = 0
No_Business_interval[is.na(No_Business_interval) == T] = 0 
operation_interval[is.na(operation_interval) == T] = 0 

PB_cluster$Business_interval = as.numeric(Business_interval)
PB_cluster$No_Business_interval = as.numeric(No_Business_interval)
PB_cluster$operation_interval = as.numeric(operation_interval)

```


calendar_updated
Same as Prediction part, we transformed the categorical variables into numeric variables as the day after last updated. For example, "a week ago" will be replaced by 7. 
```{r}
PB_cluster$calendar_updated = PB_lm$calendar_updated
```


weekly_price and monthly_price

The feature engineering process is same as what I did in prediction part. I filled the missing value of weekly_price and monthly_price using the daily price * the number of day(7 for week and 30 for month). And calculate the discount_ratio, which is equal to weekly_price dividing by (daily price times number of day). This feature can measure how much discount that this airbnb offer.
The only difference with **Step II Prediction** is that, in predictions, we measured whether offering discount or not.
```{r}
# weekly_price

#summary(PB_cluster$weekly_price)
for (i in 1:length(PB_cluster$weekly_price)) {
        if (is.na(PB_cluster$weekly_price[i]) == T){
                PB_cluster$weekly_price[i] = PB_cluster$price[i]*7
        }
}

weekly_discount_ratio = (PB_cluster$weekly_price)/(PB_cluster$price*7)
weekly_discount_ratio[is.na(weekly_discount_ratio) == T] = 1
#summary(weekly_discount_ratio)
PB_cluster$weekly_discount_ratio = weekly_discount_ratio

# monthly_price
#summary(PB_cluster$monthly_price)
for (i in 1:length(PB_cluster$monthly_price)) {
        if (is.na(PB_cluster$monthly_price[i]) == T){
                PB_cluster$monthly_price[i] = PB_cluster$price[i]*30
        }
}

monthly_discount_ratio = (PB_cluster$monthly_price)/(PB_cluster$price*30)
monthly_discount_ratio[is.na(monthly_discount_ratio) == T] = 1
#summary(monthly_discount_ratio)
PB_cluster$monthly_discount_ratio = monthly_discount_ratio
```



**outlier analysis** 
K-means and hierarchical clustering analysis are sensitive with outlier. According to the analysis in **Step II Prediction**. I delete 3 point which the price is extremely large (>1000). 
```{r}
PB_cluster = PB_cluster[PB_cluster$price <1000,]
```







#### K-means modeling
This dataset is used for K-means, I keep all the numeric variables.
```{r}
PB_kmeans = select(PB_cluster, c(host_response_rate,host_listings_count , host_total_listings_count,
                      accommodates, bathrooms ,bedrooms,beds,price,security_deposit,  cleaning_fee,
                   guests_included,   extra_people,     minimum_nights,     maximum_nights,
                   calendar_updated ,availability_30,  availability_60, availability_90, availability_365,
                   number_of_reviews,review_scores_rating, review_scores_accuracy ,review_scores_cleanliness,
                   review_scores_checkin,review_scores_communication, review_scores_location, review_scores_value,
                   calculated_host_listings_count, reviews_per_month, Business_interval, No_Business_interval,
                   operation_interval,weekly_discount_ratio, monthly_discount_ratio))
```



```{r}
PB_kmeans_2 = select(PB_cluster, c(host_response_rate,host_listings_count , host_total_listings_count,
                      accommodates, bathrooms ,bedrooms,beds,price,security_deposit,  cleaning_fee,
                   guests_included,   extra_people,     minimum_nights,     maximum_nights,
                   calendar_updated ,
                   number_of_reviews,review_scores_rating, review_scores_accuracy ,review_scores_cleanliness,
                   review_scores_checkin,review_scores_communication, review_scores_location, review_scores_value,
                   calculated_host_listings_count, reviews_per_month, Business_interval, No_Business_interval,
                   operation_interval,weekly_discount_ratio, monthly_discount_ratio))
```





```{r}
PB_kmeans.norm <- sapply(PB_kmeans_2, scale)
summary(PB_kmeans)
```


```{r}
#Elbow Method for finding the optimal number of clusters
set.seed(123)
# Compute and plot wss for k = 1 to k = 10.
k.max <- 10
data <- PB_kmeans.norm
wss <- sapply(1:k.max, 
              function(k){mean(kmeans(data, k)$withinss)})
wss
plot(1:k.max, wss,
     type="b", pch = 19, frame = FALSE, 
     xlab="Number of clusters K",
     ylab="Average Withinâˆ’Cluster Squared Distance",
     main = "COMPARING DIFFERENT CHOICES OF k IN TERMS OF OVERALL AVERAGE WITHIN-CLUSTER DISTANCE",
     cex.main=0.8,cex.lab=0.7, cex.axis=0.8)

```


```{r}
set.seed(123)
km <- kmeans(PB_kmeans.norm, 4)
Clusters = as.data.frame(km$centers)
Clusters = cbind(Clusters,count = km$size)
Clusters
```



#### Hierarchical Clustering
```{r}
PB_hierarchical = PB_kmeans
PB_hierarchical.norm <- sapply(PB_hierarchical, scale)
#summary(PB_hierarchical)
```

```{r}
library(factoextra)

result <- dist(PB_hierarchical, method = "euclidean")
result_hc <- hclust(d = result, method = "ward.D2")

plot(result_hc)
rect.hclust(result_hc,k=2)
```



```{r}
#fviz_dend(result_hc, cex = 0.6)
'''fviz_dend(result_hc, k = 4, 
          cex = 0.5, 
          k_colors = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
          color_labels_by_k = TRUE, 
          rect = TRUE          
)
'''
```






### II. Show your code and results, and name each of your clusters. In 1-2 paragraphs, describe the process that you used.










